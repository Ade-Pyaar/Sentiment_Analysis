{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import re\n",
    "import string\n",
    "\n",
    "import joblib\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('my_cleaned.csv')\n",
    "df.drop('tag', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = {'positive':1, 'neutral':0, 'negative':-1}\n",
    "df['class'] = df['class'].map(le)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CleanText(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def remove_mentions(self, input_text):\n",
    "        return re.sub(r'@\\w+', '', input_text)\n",
    "    \n",
    "    def remove_hashtags(self, input_text):\n",
    "        return re.sub(r'#([^\\s]+)', '', input_text)\n",
    "    \n",
    "    def remove_newlines(self, input_text):\n",
    "        return input_text.replace('\\n', '')\n",
    "    \n",
    "    def remove_urls(self, input_text):\n",
    "        return re.sub(r'((www\\.[^\\s]+)|(https?://[^\\s]+))', '', input_text)\n",
    "    \n",
    "    def emoji_oneword(self, input_text):\n",
    "        emoji_pattern = re.compile(\n",
    "            \"[\"\n",
    "            \"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "            \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "            \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "            \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "            \"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "            \"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "            \"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "            \"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "            \"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "            \"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "            \"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "            \"\\U000024C2-\\U0001F251\" \n",
    "            \"]+\")\n",
    "        return emoji_pattern.sub('', input_text)\n",
    "    \n",
    "    def remove_puntuaction(self, input_text):\n",
    "        punct = string.punctuation\n",
    "        trantab = str.maketrans(punct, len(punct)*' ')\n",
    "        return input_text.translate(trantab)\n",
    "    \n",
    "    def to_lower(self, input_text):\n",
    "        return input_text.lower()\n",
    "    \n",
    "    def remove_stopwords(self, input_text):\n",
    "        stopwords_list = stopwords.words('english')\n",
    "        whitelist = [\"n't\", \"not\", \"no\"]\n",
    "        words = input_text.split()\n",
    "        clean_words = [word for word in words if (word not in stopwords_list or word in whitelist) and len(word) > 1]\n",
    "        return ' '.join(clean_words)\n",
    "    \n",
    "    def lemmatizing(self, input_text):\n",
    "        lematize = WordNetLemmatizer()\n",
    "        sentence_words = word_tokenize(input_text)\n",
    "        stemmed_words = [lematize.lemmatize(word, pos='v') for word in sentence_words]\n",
    "        return ' '.join(stemmed_words)\n",
    "    \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, **transform_params):\n",
    "        clean_X = X.apply(self.remove_mentions).apply(self.remove_hashtags).apply(self.remove_newlines).apply(self.remove_urls).apply(self.emoji_oneword).apply(self.remove_puntuaction).apply(self.to_lower).apply(self.remove_stopwords).apply(self.lemmatizing)\n",
    "        return clean_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train_and_test:\n",
    "    def __init__(self, df, test_size=0.3, save_model=False, vectorizer='count', seed=42):\n",
    "        self._df = df\n",
    "        self._test_size = test_size\n",
    "        self._save_model = save_model\n",
    "        self._vectorizer = vectorizer\n",
    "        self._seed = seed\n",
    "        self._text_cleaner = CleanText()\n",
    "        self._countvect = CountVectorizer()\n",
    "        self._tfidf_vect = TfidfVectorizer()\n",
    "        self._nb_tf_model = MultinomialNB()\n",
    "        self._nb_count_model = MultinomialNB()\n",
    "        self.x_test = None\n",
    "        self.y_test = None\n",
    "        self.predict = None\n",
    "    \n",
    "    \n",
    "    def train_and_test(self):\n",
    "        cleaned_data = self._text_cleaner.fit_transform(self._df.tweet_text)\n",
    "        self._df.tweet_text = cleaned_data\n",
    "        X = self._df.tweet_text\n",
    "        y = self._df['class']\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=self._test_size, random_state=self._seed, stratify=y)\n",
    "        \n",
    "        self.y_test = pd.DataFrame(y_test, columns=['class'])\n",
    "        self.y_test.to_csv('y_test.csv', index=False)\n",
    "\n",
    "        if self._vectorizer == 'count':\n",
    "            X_count_train = self._countvect.fit_transform(X_train)\n",
    "            self._nb_count_model.fit(X_count_train, y_train)\n",
    "\n",
    "            X_count_test = self._countvect.transform(X_test)\n",
    "            self.x_test = pd.DataFrame(X_count_test, columns=['class'])\n",
    "            self.x_test.to_csv('X_test.csv', index=False)\n",
    "            \n",
    "            nb_count_predict = self._nb_count_model.predict(X_count_test)\n",
    "            \n",
    "            self.predict = pd.DataFrame(nb_count_predict, columns=['class'])\n",
    "            self.predict.to_csv('prediction.csv', index=False)\n",
    "\n",
    "            print('The scores for the model using CountVectorizer...')\n",
    "            print(\"F1 Score: \", f1_score(y_test, nb_count_predict, average='macro') )\n",
    "            print(f\"Accuracy Score: \", accuracy_score(y_test, nb_count_predict))\n",
    "\n",
    "            if self._save_model:\n",
    "                joblib.dump(self._nb_count_model, 'nb_count_model.pkl')\n",
    "                print(\"Model saved as 'nb_count_model.pkl'!\")\n",
    "\n",
    "        elif self._vectorizer == 'tfidf':\n",
    "            X_tf_train = self._tfidf_vect.fit_transform(X_train)\n",
    "            self._nb_tf_model.fit(X_tf_train, y_train)\n",
    "\n",
    "            X_tfidf_test = self._tfidf_vect.transform(X_test)\n",
    "            self.x_test = pd.DataFrame(X_tfidf_test, columns=['class'])\n",
    "            self.x_test.to_csv('X_test.csv', index=False)\n",
    "            \n",
    "            nb_tf_predict = self._nb_tf_model.predict(X_tfidf_test)\n",
    "            \n",
    "            self.predict = pd.DataFrame(nb_tf_predict, columns=['class'])\n",
    "            self.predict.to_csv('prediction.csv', index=False)\n",
    "\n",
    "            print('The scores for the model using TfidfVectorizer...')\n",
    "            print(\"F1 Score: \", f1_score(y_test, nb_tf_predict, average='micro'))\n",
    "            print(\"Accuracy Score: \", accuracy_score(y_test, nb_tf_predict))\n",
    "\n",
    "            if self._save_model:\n",
    "                joblib.dump(self._nb_tf_model, 'nb_tf_model.pkl')\n",
    "                print(\"Model saved as 'nb_tf_model.pkl'!\")\n",
    "        else:\n",
    "            print(\"Invalid vectorizer. Choose between 'count' and 'tfidf' \")\n",
    "        \n",
    "    \n",
    "    \n",
    "    def user_predict(self, input_text):\n",
    "        input_text = pd.Series(input_text)\n",
    "        clean_text = self._text_cleaner.transform(input_text)\n",
    "\n",
    "        if self._vectorizer == 'count':\n",
    "            count_text = self._countvect.transform(clean_text)\n",
    "            predict = self._nb_count_model.predict(count_text).item()\n",
    "            if predict == 1:\n",
    "                print('The input text is positive.')\n",
    "            elif predict == 0:\n",
    "                print('The input text is neutral.')\n",
    "            else:\n",
    "                print('the input text is negative.')\n",
    "        elif self._vectorizer == 'tfidf':\n",
    "            count_text = self._tfidf_vect.transform(clean_text)\n",
    "            predict = self._nb_tf_model.predict(count_text).item()\n",
    "            if predict == 1:\n",
    "                print('The input text is positive.')\n",
    "            elif predict == 0:\n",
    "                print('The input text is neutral.')\n",
    "            else:\n",
    "                print('the input text is negative.')\n",
    "        else:\n",
    "            print(\"Invalid vectorizer. Choose between 'count' and 'tfidf' \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_class = Train_and_test(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scores for the model using CountVectorizer...\n",
      "F1 Score:  0.7804102286075719\n",
      "Accuracy Score:  0.847457627118644\n"
     ]
    }
   ],
   "source": [
    "my_class.train_and_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_class.user_predict('it was bad')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
